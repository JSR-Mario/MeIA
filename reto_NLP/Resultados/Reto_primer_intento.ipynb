{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvVysoOAdBN6"
      },
      "outputs": [],
      "source": [
        "# Sentiment Analysis en Pueblos Mágicos\n",
        "\n",
        "# 1. Instalación de librerías\n",
        "def install_dependencies():\n",
        "    !pip install pandas \"numpy<2.0\" scikit-learn openpyxl transformers torch sentencepiece datasets evaluate sacremoses tqdm\n",
        "\n",
        "# 2. Carga de datos\n",
        "def load_data(train_path, test_path):\n",
        "    import pandas as pd\n",
        "    train = pd.read_excel(train_path)\n",
        "    test  = pd.read_excel(test_path)\n",
        "    return train, test\n",
        "\n",
        "# 3. Limpieza básica del texto\n",
        "def preprocess_text(df):\n",
        "    import re\n",
        "    df['clean'] = (\n",
        "        df['Review']\n",
        "        .str.lower()\n",
        "        .str.replace(r\"<[^>]+>\", \" \", regex=True)\n",
        "        .str.replace(r\"[^a-záéíóúñü ]\", \" \", regex=True)\n",
        "        .str.replace(r\"\\s+\", \" \", regex=True)\n",
        "        .str.strip()\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# 4. Balanceo por aumentación de datos en clases minoritarias, como hay mas datos de 5 estrellas, generamos datos para las otras estellas usando traducción al ingles y de regreso\n",
        "from tqdm.auto import tqdm\n",
        "import torch\n",
        "import os\n",
        "\n",
        "def balance_with_back_translation(df, target_count=None, batch_size=128, checkpoint_path='train_balanced.csv'):\n",
        "    import pandas as pd\n",
        "    from math import ceil\n",
        "    from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "    # Verificar si ya existe el checkpoint\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        print(f\"Cargando datos balanceados desde checkpoint: {checkpoint_path}\")\n",
        "        return pd.read_csv(checkpoint_path)\n",
        "\n",
        "    print(\"Generando datos balanceados\")\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Carga de modelos de traducción y envío a GPU\n",
        "    me2en_tok = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-es-en')\n",
        "    me2en = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-es-en').to(device)\n",
        "    en2me_tok = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-es')\n",
        "    en2me = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-es').to(device)\n",
        "\n",
        "    counts = df['Polarity'].value_counts().to_dict()\n",
        "    max_count = target_count or max(counts.values())\n",
        "    augmented = []  # lista de (texto, polaridad)\n",
        "\n",
        "    for polarity, cnt in counts.items():\n",
        "        if cnt < max_count:\n",
        "            needed = max_count - cnt\n",
        "            samples = df[df['Polarity'] == polarity]['clean'].tolist()\n",
        "            reps = ceil(needed / len(samples))\n",
        "            pool = samples * reps\n",
        "            to_aug = pool[:needed]\n",
        "\n",
        "            batch_augmented = []\n",
        "            for i in tqdm(range(0, len(to_aug), batch_size), desc=f'Aug Polarity {polarity}'):\n",
        "                batch_texts = to_aug[i:i+batch_size]\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    # es -> en\n",
        "                    enc = me2en_tok(batch_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "                    en_ids = me2en.generate(**enc, max_length=128)\n",
        "                    en_texts = me2en_tok.batch_decode(en_ids, skip_special_tokens=True)\n",
        "\n",
        "                    # en -> es\n",
        "                    dec = en2me_tok(en_texts, return_tensors='pt', padding=True, truncation=True).to(device)\n",
        "                    es_ids = en2me.generate(**dec, max_length=128)\n",
        "                    aug_texts = en2me_tok.batch_decode(es_ids, skip_special_tokens=True)\n",
        "\n",
        "                batch_augmented.extend([(t, polarity) for t in aug_texts])\n",
        "\n",
        "            if batch_augmented:\n",
        "                augmented.extend(batch_augmented)\n",
        "                df_partial = pd.DataFrame({\n",
        "                    'Review': [t for t,_ in batch_augmented],\n",
        "                    'Polarity': [p for _,p in batch_augmented],\n",
        "                    'clean': [t for t,_ in batch_augmented]\n",
        "                })\n",
        "                df_partial.to_csv(f'augmented_polarity_{int(polarity)}.csv', mode='a', header=not pd.io.common.file_exists(f'augmented_polarity_{int(polarity)}.csv'), index=False, encoding='utf-8')\n",
        "\n",
        "    texts, labels = zip(*augmented) if augmented else ([], [])\n",
        "    aug_df = pd.DataFrame({'Review': texts, 'Polarity': labels, 'clean': texts})\n",
        "    balanced_df = pd.concat([df, aug_df], ignore_index=True)\n",
        "\n",
        "    # Guardamos un checkpoint\n",
        "    balanced_df.to_csv(checkpoint_path, index=False, encoding='utf-8')\n",
        "    print(f\"💾 Datos balanceados guardados en: {checkpoint_path}\")\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "# 5. Domain-Adaptive Pretraining\n",
        "def domain_adaptive_pretraining(texts, base_model='PlanTL-GOB-ES/roberta-base-bne', checkpoint_dir='domain_adapted_model'):\n",
        "    from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "    from datasets import Dataset\n",
        "    import os\n",
        "\n",
        "    # Verificar si ya existe el checkpoint\n",
        "    if os.path.exists(checkpoint_dir) and os.path.exists(f\"{checkpoint_dir}_tokenizer\"):\n",
        "        print(f\"Cargando modelo adaptado al dominio desde checkpoint: {checkpoint_dir}\")\n",
        "        model = AutoModelForMaskedLM.from_pretrained(checkpoint_dir)\n",
        "        tokenizer = AutoTokenizer.from_pretrained(f\"{checkpoint_dir}_tokenizer\")\n",
        "        return model, tokenizer\n",
        "\n",
        "    print(\"Realizando adaptación al dominio\")\n",
        "    tok = AutoTokenizer.from_pretrained(base_model)\n",
        "    model = AutoModelForMaskedLM.from_pretrained(base_model)\n",
        "    ds = Dataset.from_dict({'text': texts})\n",
        "    def tok_fn(x): return tok(x['text'], truncation=True, padding='max_length', max_length=128)\n",
        "    tok_ds = ds.map(tok_fn, batched=True)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(tok, mlm=True, mlm_probability=0.15)\n",
        "    args = TrainingArguments(\n",
        "        output_dir='domain_adapt', num_train_epochs=3,\n",
        "        per_device_train_batch_size=32, logging_steps=100, save_steps=500,\n",
        "        learning_rate=2e-5, weight_decay=0.01\n",
        "    )\n",
        "    trainer = Trainer(model=model, args=args, train_dataset=tok_ds, data_collator=data_collator)\n",
        "    trainer.train()\n",
        "\n",
        "    # Guardar checkpoint\n",
        "    model.save_pretrained(checkpoint_dir)\n",
        "    tok.save_pretrained(f\"{checkpoint_dir}_tokenizer\")\n",
        "    print(f\"Modelo adaptado al dominio guardado en: {checkpoint_dir}\")\n",
        "\n",
        "    return model, tok\n",
        "\n",
        "# 6. Fine‑tuning con validación cruzada estratificada\n",
        "def cross_val_finetune(train_df, model, tokenizer, n_splits=4):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    from datasets import Dataset\n",
        "    from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "    from sklearn.metrics import f1_score, mean_absolute_error\n",
        "    import torch\n",
        "\n",
        "    # Forzar compatibilidad con NumPy\n",
        "    import os\n",
        "    os.environ['NUMPY_EXPERIMENTAL_ARRAY_FUNCTION'] = '0'\n",
        "\n",
        "    # Resetear índices para evitar problemas con el acceso a datos\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "    metrics = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df['clean'], train_df['Polarity']), start=1):\n",
        "        print(f\"Procesando fold {fold}/{n_splits}\")\n",
        "\n",
        "        # Preparar datasets de entrenamiento y validación usando .iloc para acceso seguro\n",
        "        train_texts = train_df.iloc[train_idx]['clean'].tolist()\n",
        "        train_labels = [int(label - 1) for label in train_df.iloc[train_idx]['Polarity'].tolist()]\n",
        "        val_texts = train_df.iloc[val_idx]['clean'].tolist()\n",
        "        val_labels = [int(label - 1) for label in train_df.iloc[val_idx]['Polarity'].tolist()]\n",
        "        train_encodings = tokenizer(train_texts, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
        "        val_encodings = tokenizer(val_texts, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
        "\n",
        "        class CustomDataset(torch.utils.data.Dataset):\n",
        "            def __init__(self, encodings, labels):\n",
        "                self.encodings = encodings\n",
        "                self.labels = labels\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
        "                item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "                return item\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.labels)\n",
        "\n",
        "        train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "        val_dataset = CustomDataset(val_encodings, val_labels)\n",
        "\n",
        "        # Crear y entrenar modelo\n",
        "        model_cls = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model.name_or_path if hasattr(model, 'name_or_path') else 'PlanTL-GOB-ES/roberta-base-bne',\n",
        "            num_labels=5,\n",
        "            problem_type=\"single_label_classification\"\n",
        "        )\n",
        "\n",
        "        args = TrainingArguments(\n",
        "            output_dir=f'cv_fold{fold}',\n",
        "            num_train_epochs=4,\n",
        "            per_device_train_batch_size=8,\n",
        "            logging_steps=200,\n",
        "            save_strategy=\"no\",\n",
        "            learning_rate=2e-5,\n",
        "            weight_decay=0.01\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model_cls,\n",
        "            args=args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset\n",
        "        )\n",
        "        trainer.train()\n",
        "\n",
        "        print(f\"Evaluando fold {fold}\")\n",
        "        model_cls.eval()\n",
        "        device = next(model_cls.parameters()).device\n",
        "\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "            for i in range(0, len(val_texts), 512):  # Procesar en lotes de 512\n",
        "                batch_texts = val_texts[i:i+512]\n",
        "                batch_encodings = tokenizer(batch_texts, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
        "                batch_encodings = {k: v.to(device) for k, v in batch_encodings.items()}\n",
        "\n",
        "                outputs = model_cls(**batch_encodings)\n",
        "                predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "                all_preds.extend(predictions.cpu().numpy())\n",
        "\n",
        "        # Convertir de vuelta a etiquetas originales (1-5)\n",
        "        true_labels = [label + 1 for label in val_labels]\n",
        "        pred_labels = [pred + 1 for pred in all_preds]\n",
        "\n",
        "        f1 = f1_score(val_labels, all_preds, average='macro')\n",
        "        mae = mean_absolute_error(true_labels, pred_labels)\n",
        "\n",
        "        metrics.append({'fold': fold, 'f1_macro': f1, 'mae': mae})\n",
        "        print(f\"Fold {fold} - F1 Macro: {f1:.4f}, MAE: {mae:.4f}\")\n",
        "\n",
        "    return metrics\n",
        "\n",
        "\n",
        "def check_checkpoint_status():\n",
        "    \"\"\"Verifica qué checkpoints existen y su tamaño\"\"\"\n",
        "    import os\n",
        "    print(\"📋 ESTADO DE LOS CHECKPOINTS:\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Datos balanceados\n",
        "    if os.path.exists('train_balanced.csv'):\n",
        "        size = os.path.getsize('train_balanced.csv') / (1024*1024)  # MB\n",
        "        print(f\"Datos balanceados: train_balanced.csv ({size:.1f} MB)\")\n",
        "    else:\n",
        "        print(\"Datos balanceados: NO encontrados\")\n",
        "\n",
        "    # Modelo adaptado al dominio\n",
        "    if os.path.exists('domain_adapted_model') and os.path.exists('domain_adapted_model_tokenizer'):\n",
        "        print(\"Modelo adaptado al dominio: domain_adapted_model/\")\n",
        "    else:\n",
        "        print(\"Modelo adaptado al dominio: NO encontrado\")\n",
        "\n",
        "    # Archivos de aumentación parcial\n",
        "    aug_files = [f for f in os.listdir('.') if f.startswith('augmented_polarity_')]\n",
        "    if aug_files:\n",
        "        print(f\"Archivos de aumentación parcial: {len(aug_files)} archivos\")\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "def clean_checkpoints():\n",
        "    \"\"\"Limpia todos los checkpoints para empezar desde cero\"\"\"\n",
        "    import os\n",
        "    import shutil\n",
        "\n",
        "    print(\"LIMPIANDO CHECKPOINTS...\")\n",
        "\n",
        "    # Archivos CSV\n",
        "    files_to_remove = ['train_balanced.csv'] + [f for f in os.listdir('.') if f.startswith('augmented_polarity_')]\n",
        "    for file in files_to_remove:\n",
        "        if os.path.exists(file):\n",
        "            os.remove(file)\n",
        "            print(f\"️Eliminado: {file}\")\n",
        "\n",
        "    # Directorios de modelos\n",
        "    dirs_to_remove = ['domain_adapted_model', 'domain_adapted_model_tokenizer', 'domain_adapt']\n",
        "    for dir_name in dirs_to_remove:\n",
        "        if os.path.exists(dir_name):\n",
        "            shutil.rmtree(dir_name)\n",
        "            print(f\"Eliminado directorio: {dir_name}\")\n",
        "\n",
        "    # Directorios de CV\n",
        "    cv_dirs = [d for d in os.listdir('.') if d.startswith('cv_fold')]\n",
        "    for cv_dir in cv_dirs:\n",
        "        if os.path.exists(cv_dir):\n",
        "            shutil.rmtree(cv_dir)\n",
        "            print(f\"️Eliminado directorio: {cv_dir}\")\n",
        "\n",
        "    print(\"Limpieza completada\")\n",
        "\n",
        "def run_complete_pipeline(train_path, test_path, force_restart=False):\n",
        "    \"\"\"\n",
        "    Ejecuta el pipeline completo con manejo inteligente de checkpoints\n",
        "\n",
        "    Args:\n",
        "        train_path: Ruta al archivo de entrenamiento\n",
        "        test_path: Ruta al archivo de test\n",
        "        force_restart: Si True, ignora checkpoints y empieza desde cero\n",
        "    \"\"\"\n",
        "    print(\"INICIANDO PIPELINE DE SENTIMENT ANALYSIS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    if force_restart:\n",
        "        clean_checkpoints()\n",
        "\n",
        "    check_checkpoint_status()\n",
        "\n",
        "    # 1. Cargar datos\n",
        "    print(\"\\n1️⃣  CARGANDO DATOS...\")\n",
        "    train, test = load_data(train_path, test_path)\n",
        "\n",
        "    # 2. Preprocesar\n",
        "    print(\"\\n2️⃣  PREPROCESANDO DATOS...\")\n",
        "    train = preprocess_text(train)\n",
        "    test = preprocess_text(test)\n",
        "\n",
        "    # 3. Balancear\n",
        "    print(\"\\n3️⃣  BALANCEANDO DATOS...\")\n",
        "    train_bal = balance_with_back_translation(train)\n",
        "\n",
        "    # 4. Adaptación al dominio\n",
        "    print(\"\\n4️⃣  ADAPTACIÓN AL DOMINIO...\")\n",
        "    model_da, tokenizer = domain_adaptive_pretraining(train_bal['clean'])\n",
        "\n",
        "    # 5. Validación cruzada\n",
        "    print(\"\\n5️⃣  VALIDACIÓN CRUZADA...\")\n",
        "    cv_metrics = cross_val_finetune(train_bal, model_da, tokenizer)\n",
        "    print(\"\\nRESULTADOS DE VALIDACIÓN CRUZADA:\")\n",
        "    for metric in cv_metrics:\n",
        "        print(f\"Fold {metric['fold']}: F1={metric['f1_macro']:.4f}, MAE={metric['mae']:.4f}\")\n",
        "\n",
        "    # 6. Entrenamiento final\n",
        "    print(\"\\n6️⃣  ENTRENAMIENTO FINAL Y PREDICCIONES...\")\n",
        "    final_train_and_predict(train_bal, test, model_da, tokenizer)\n",
        "\n",
        "    print(\"\\nPIPELINE COMPLETADO\")\n",
        "    print(\"Archivo de predicciones: predicciones.txt\")\n",
        "\n",
        "    return cv_metrics\n",
        "\n",
        "def final_train_and_predict(train_df, test_df, model, tokenizer, output_path='predicciones.txt'):\n",
        "    from datasets import Dataset\n",
        "    from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "    import torch\n",
        "\n",
        "    # Resetear índices\n",
        "    train_df = train_df.reset_index(drop=True)\n",
        "    test_df = test_df.reset_index(drop=True)\n",
        "\n",
        "    # Preparar datos de entrenamiento\n",
        "    train_texts = train_df['clean'].tolist()\n",
        "    labels = [int(l-1) for l in train_df['Polarity'].tolist()]\n",
        "\n",
        "    ds_train = Dataset.from_dict({'text': train_texts, 'label': labels})\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "    ds_train = ds_train.map(tokenize_function, batched=True)\n",
        "    ds_train = ds_train.remove_columns(['text'])\n",
        "    ds_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "\n",
        "    # Crear y entrenar modelo final\n",
        "    model_cls = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model.name_or_path if hasattr(model, 'name_or_path') else 'PlanTL-GOB-ES/roberta-base-bne',\n",
        "        num_labels=5,\n",
        "        problem_type=\"single_label_classification\"\n",
        "    )\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir='final_train',\n",
        "        num_train_epochs=3,\n",
        "        per_device_train_batch_size=8,\n",
        "        save_strategy=\"no\",\n",
        "        logging_steps=200,\n",
        "        learning_rate=2e-5,\n",
        "        weight_decay=0.01\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(model=model_cls, args=args, train_dataset=ds_train)\n",
        "    trainer.train()\n",
        "\n",
        "    # Predicciones en test\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model_cls.to(device)\n",
        "    model_cls.eval()\n",
        "\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        for idx in range(len(test_df)):\n",
        "            _id = test_df.iloc[idx]['ID']\n",
        "            txt = test_df.iloc[idx]['clean']\n",
        "\n",
        "            inputs = tokenizer(txt, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
        "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model_cls(**inputs).logits\n",
        "                pred = torch.argmax(logits, dim=1).item() + 1\n",
        "\n",
        "            f.write(f\"MeIA {_id} {pred}\\n\")\n",
        "\n",
        "    print(f\"Archivo de salida generado: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "vCQQlQAltqj1",
        "outputId": "f99c78d5-e4f1-4177-962a-0fde98c54e06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting numpy<2.0\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (2.14.4)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from sacremoses) (8.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.20.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m616.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sacremoses, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, evaluate\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed evaluate-0.4.4 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sacremoses-0.1.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "6db5b531541c4fb5ad0611adfdced514",
              "pip_warning": {
                "packages": [
                  "numpy",
                  "nvidia"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "install_dependencies()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "93db870743c64a19811ddbecf922d15a",
            "14848ff279864c4bb9b7444af32b98ca",
            "a4e744b90b17416a86d010b32fe16dcd",
            "e70c8456e01f4d07b2660f6c209670e0",
            "bc435a97878c4ec7afb7a33c0fd3f9af",
            "85c7301a26104a82bf2056d20fb1d913",
            "3c362840409e4fe985b00beb9f1eaece",
            "e5e46717e73b4cfc8a38320a71fc3974",
            "4ec52e9255d840868a725f87a2032828",
            "264d9eeb24f94909ba4c6d86dacb8613",
            "a9a956e726764fb2824a7b71a3adb5a7",
            "defc1dccd5eb41fbb5535bbad792ff97",
            "58ae85986b04462a895eac5ccb05577f",
            "4f4fd905c5074635b496c43f8c90f70e",
            "90d4191d9700412cb1c274b071956045",
            "2993f64f14564c3f9e50f1ef525f2ecb",
            "f810e85d0ff74ed4a3e700af6b630c1e",
            "d4905fd4f13a4585a01b03f329a213fc",
            "99f25ecbc7f6431db1a83e273f3d2e9e",
            "6cbee0ad7a1d47c6bce4b73da2eddb06",
            "49c080bab04b4346a7bfe3df4c37be1c",
            "952d276b751e4ea1a4fa762831ef4315"
          ]
        },
        "id": "5nch6nwwTDcQ",
        "outputId": "4903182a-1892-4538-a7a8-d07f014fa604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INICIANDO PIPELINE DE SENTIMENT ANALYSIS\n",
            "============================================================\n",
            "📋 ESTADO DE LOS CHECKPOINTS:\n",
            "--------------------------------------------------\n",
            "Datos balanceados: train_balanced.csv (4.8 MB)\n",
            "Modelo adaptado al dominio: NO encontrado\n",
            "--------------------------------------------------\n",
            "\n",
            "1️⃣  CARGANDO DATOS...\n",
            "\n",
            "2️⃣  PREPROCESANDO DATOS...\n",
            "\n",
            "3️⃣  BALANCEANDO DATOS...\n",
            "Cargando datos balanceados desde checkpoint: train_balanced.csv\n",
            "\n",
            "4️⃣  ADAPTACIÓN AL DOMINIO...\n",
            "Realizando adaptación al dominio\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93db870743c64a19811ddbecf922d15a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuanmario\u001b[0m (\u001b[33mjuanmario-unam-universidad-nacional-aut-noma-de-m-xico\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250623_170025-jzclruyr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/juanmario-unam-universidad-nacional-aut-noma-de-m-xico/huggingface/runs/jzclruyr' target=\"_blank\">domain_adapt</a></strong> to <a href='https://wandb.ai/juanmario-unam-universidad-nacional-aut-noma-de-m-xico/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/juanmario-unam-universidad-nacional-aut-noma-de-m-xico/huggingface' target=\"_blank\">https://wandb.ai/juanmario-unam-universidad-nacional-aut-noma-de-m-xico/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/juanmario-unam-universidad-nacional-aut-noma-de-m-xico/huggingface/runs/jzclruyr' target=\"_blank\">https://wandb.ai/juanmario-unam-universidad-nacional-aut-noma-de-m-xico/huggingface/runs/jzclruyr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [564/564 09:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>2.584100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.466500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.376700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.319900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.307300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo adaptado al dominio guardado en: domain_adapted_model\n",
            "\n",
            "5️⃣  VALIDACIÓN CRUZADA...\n",
            "Procesando fold 1/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2252' max='2252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2252/2252 07:33, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.259400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.105400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.011900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.768300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.719900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.582000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.335400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.327500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.212400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.139900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.129300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluando fold 1\n",
            "Fold 1 - F1 Macro: 0.6333, MAE: 0.4173\n",
            "Procesando fold 2/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2252' max='2252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2252/2252 07:33, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.288600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.101000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.974900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.768800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.708800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.624900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.324900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.330100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.238000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.132700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.120400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluando fold 2\n",
            "Fold 2 - F1 Macro: 0.6224, MAE: 0.4207\n",
            "Procesando fold 3/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2252' max='2252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2252/2252 07:33, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.214500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.092000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.988400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.752500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.686400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.575700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.357600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.349900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.224800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.142700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.108500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluando fold 3\n",
            "Fold 3 - F1 Macro: 0.6208, MAE: 0.4360\n",
            "Procesando fold 4/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2252' max='2252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2252/2252 07:34, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.250200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.049500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.020900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.713900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.760400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.602500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.335000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.339800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.182900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.107400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.118900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluando fold 4\n",
            "Fold 4 - F1 Macro: 0.5988, MAE: 0.4560\n",
            "\n",
            "RESULTADOS DE VALIDACIÓN CRUZADA:\n",
            "Fold 1: F1=0.6333, MAE=0.4173\n",
            "Fold 2: F1=0.6224, MAE=0.4207\n",
            "Fold 3: F1=0.6208, MAE=0.4360\n",
            "Fold 4: F1=0.5988, MAE=0.4560\n",
            "\n",
            "6️⃣  ENTRENAMIENTO FINAL Y PREDICCIONES...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "defc1dccd5eb41fbb5535bbad792ff97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/6000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2250/2250 07:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.274700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>1.049800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.949200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.720200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.681900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.649600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.512000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.323800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.294800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.293300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivo de salida generado: predicciones.txt\n",
            "\n",
            "PIPELINE COMPLETADO\n",
            "Archivo de predicciones: predicciones.txt\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'fold': 1, 'f1_macro': 0.6333192063943998, 'mae': 0.41733333333333333},\n",
              " {'fold': 2, 'f1_macro': 0.622407988807034, 'mae': 0.4206666666666667},\n",
              " {'fold': 3, 'f1_macro': 0.6208227596772979, 'mae': 0.436},\n",
              " {'fold': 4, 'f1_macro': 0.5988215083060047, 'mae': 0.456}]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_complete_pipeline('MeIA_2025_train.xlsx', 'MeIA_2025_test_wo_labels.xlsx')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14848ff279864c4bb9b7444af32b98ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85c7301a26104a82bf2056d20fb1d913",
            "placeholder": "​",
            "style": "IPY_MODEL_3c362840409e4fe985b00beb9f1eaece",
            "value": "Map: 100%"
          }
        },
        "264d9eeb24f94909ba4c6d86dacb8613": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2993f64f14564c3f9e50f1ef525f2ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c362840409e4fe985b00beb9f1eaece": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c080bab04b4346a7bfe3df4c37be1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ec52e9255d840868a725f87a2032828": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f4fd905c5074635b496c43f8c90f70e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99f25ecbc7f6431db1a83e273f3d2e9e",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cbee0ad7a1d47c6bce4b73da2eddb06",
            "value": 6000
          }
        },
        "58ae85986b04462a895eac5ccb05577f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f810e85d0ff74ed4a3e700af6b630c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_d4905fd4f13a4585a01b03f329a213fc",
            "value": "Map: 100%"
          }
        },
        "6cbee0ad7a1d47c6bce4b73da2eddb06": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "85c7301a26104a82bf2056d20fb1d913": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90d4191d9700412cb1c274b071956045": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c080bab04b4346a7bfe3df4c37be1c",
            "placeholder": "​",
            "style": "IPY_MODEL_952d276b751e4ea1a4fa762831ef4315",
            "value": " 6000/6000 [00:01&lt;00:00, 3801.91 examples/s]"
          }
        },
        "93db870743c64a19811ddbecf922d15a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14848ff279864c4bb9b7444af32b98ca",
              "IPY_MODEL_a4e744b90b17416a86d010b32fe16dcd",
              "IPY_MODEL_e70c8456e01f4d07b2660f6c209670e0"
            ],
            "layout": "IPY_MODEL_bc435a97878c4ec7afb7a33c0fd3f9af"
          }
        },
        "952d276b751e4ea1a4fa762831ef4315": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99f25ecbc7f6431db1a83e273f3d2e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e744b90b17416a86d010b32fe16dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e46717e73b4cfc8a38320a71fc3974",
            "max": 6000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ec52e9255d840868a725f87a2032828",
            "value": 6000
          }
        },
        "a9a956e726764fb2824a7b71a3adb5a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc435a97878c4ec7afb7a33c0fd3f9af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4905fd4f13a4585a01b03f329a213fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "defc1dccd5eb41fbb5535bbad792ff97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58ae85986b04462a895eac5ccb05577f",
              "IPY_MODEL_4f4fd905c5074635b496c43f8c90f70e",
              "IPY_MODEL_90d4191d9700412cb1c274b071956045"
            ],
            "layout": "IPY_MODEL_2993f64f14564c3f9e50f1ef525f2ecb"
          }
        },
        "e5e46717e73b4cfc8a38320a71fc3974": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70c8456e01f4d07b2660f6c209670e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_264d9eeb24f94909ba4c6d86dacb8613",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a956e726764fb2824a7b71a3adb5a7",
            "value": " 6000/6000 [00:01&lt;00:00, 3212.15 examples/s]"
          }
        },
        "f810e85d0ff74ed4a3e700af6b630c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}